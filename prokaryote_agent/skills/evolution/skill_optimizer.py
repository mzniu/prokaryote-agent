"""
æŠ€èƒ½è‡ªä¼˜åŒ–å™¨ - å½“è®­ç»ƒå¤±è´¥æ—¶è‡ªåŠ¨åˆ†æåŸå› å¹¶ä¼˜åŒ–æŠ€èƒ½å®ç°

è®¾è®¡æ€è·¯ï¼š
1. æ£€æµ‹è¿ç»­è®­ç»ƒå¤±è´¥ï¼ˆå¦‚è¿ç»­3æ¬¡å¤±è´¥ï¼‰
2. åˆ†æå¤±è´¥åŸå› ï¼ˆäº§å‡ºç‰©å¤ªå°ã€çŸ¥è¯†å­˜å‚¨ä¸º0ã€åˆ†ææ·±åº¦ä¸è¶³ç­‰ï¼‰
3. ç”Ÿæˆä¼˜åŒ–å»ºè®®æˆ–è‡ªåŠ¨ä¼˜åŒ–æŠ€èƒ½ä»£ç 
4. é‡æ–°è®­ç»ƒéªŒè¯ä¼˜åŒ–æ•ˆæœ

æ ¸å¿ƒæµç¨‹ï¼š
  train() â†’ fail â†’ analyze_failure() â†’ optimize_skill() â†’ retrain()
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class SkillOptimizer:
    """æŠ€èƒ½è‡ªä¼˜åŒ–å™¨"""

    # å¤±è´¥åŸå› ç±»å‹
    FAILURE_TYPES = {
        'output_too_small': 'äº§å‡ºç‰©ä½“é‡è¿‡å°',
        'no_knowledge_stored': 'çŸ¥è¯†å­˜å‚¨é‡ä¸º0',
        'low_analysis_depth': 'åˆ†ææ·±åº¦ä¸è¶³',
        'missing_legal_refs': 'ç¼ºå°‘æ³•å¾‹å¼•ç”¨',
        'low_relevance': 'ç›¸å…³æ€§ä¸è¶³',
        'timeout': 'æ‰§è¡Œè¶…æ—¶',
        'error': 'æ‰§è¡Œé”™è¯¯',
    }

    # æ¯ç§å¤±è´¥ç±»å‹å¯¹åº”çš„ä¼˜åŒ–ç­–ç•¥
    OPTIMIZATION_STRATEGIES = {
        'output_too_small': [
            'increase_analysis_length',
            'add_more_sections',
            'use_ai_generation',
        ],
        'no_knowledge_stored': [
            'fix_storage_logic',
            'enable_web_search',
            'lower_storage_threshold',
        ],
        'low_analysis_depth': [
            'add_ai_analysis',
            'increase_search_keywords',
            'add_context_integration',
        ],
        'missing_legal_refs': [
            'add_law_search',
            'add_case_search',
            'expand_legal_categories',
        ],
        'low_relevance': [
            'improve_keyword_extraction',
            'add_semantic_search',
            'filter_irrelevant_results',
        ],
    }

    def __init__(self, max_failures: int = 3, auto_optimize: bool = False):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å™¨

        Args:
            max_failures: è§¦å‘ä¼˜åŒ–çš„æœ€å¤§å¤±è´¥æ¬¡æ•°
            auto_optimize: æ˜¯å¦è‡ªåŠ¨ä¼˜åŒ–ï¼ˆFalseæ—¶åªç”Ÿæˆå»ºè®®ï¼‰
        """
        self.max_failures = max_failures
        self.auto_optimize = auto_optimize
        self.failure_history: Dict[str, List[Dict]] = {}

    def record_failure(
        self,
        skill_id: str,
        level: int,
        eval_result: Dict[str, Any],
        execution_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        è®°å½•è®­ç»ƒå¤±è´¥

        Args:
            skill_id: æŠ€èƒ½ID
            level: å½“å‰æŠ€èƒ½ç­‰çº§
            eval_result: è¯„ä¼°ç»“æœï¼ˆåŒ…å«åˆ†æ•°ã€è¯¦ç»†åé¦ˆç­‰ï¼‰
            execution_result: æ‰§è¡Œç»“æœï¼ˆåŒ…å«äº§å‡ºç‰©ç­‰ï¼‰

        Returns:
            åŒ…å«è¿ç»­å¤±è´¥æ¬¡æ•°ã€æ˜¯å¦éœ€è¦ä¼˜åŒ–ã€å¤±è´¥åˆ†æ
        """
        if skill_id not in self.failure_history:
            self.failure_history[skill_id] = []

        failure_record = {
            'timestamp': datetime.now().isoformat(),
            'level': level,
            'score': eval_result.get('score', 0),
            'feedback': eval_result.get('feedback', ''),
            'dimensions': eval_result.get('dimensions', {}),
            'execution_result': self._extract_key_info(execution_result),
        }

        self.failure_history[skill_id].append(failure_record)

        # ç»Ÿè®¡è¿ç»­å¤±è´¥æ¬¡æ•°
        consecutive = self._count_consecutive_failures(skill_id)

        # åˆ†æå¤±è´¥åŸå› 
        failure_analysis = self.analyze_failures(skill_id)

        should_optimize = consecutive >= self.max_failures

        result = {
            'consecutive_failures': consecutive,
            'should_optimize': should_optimize,
            'failure_analysis': failure_analysis,
        }

        if should_optimize:
            logger.warning(
                "æŠ€èƒ½ %s è¿ç»­å¤±è´¥ %d æ¬¡ï¼Œå»ºè®®è¿›è¡Œä¼˜åŒ–",
                skill_id, consecutive
            )
            result['optimization_suggestions'] = \
                self.generate_optimization_suggestions(skill_id, failure_analysis)

        return result

    def record_success(self, skill_id: str):
        """è®°å½•è®­ç»ƒæˆåŠŸï¼Œæ¸…ç©ºå¤±è´¥å†å²"""
        if skill_id in self.failure_history:
            self.failure_history[skill_id] = []

    def _extract_key_info(self, execution_result: Dict) -> Dict:
        """æå–æ‰§è¡Œç»“æœçš„å…³é”®ä¿¡æ¯"""
        result = execution_result.get('result', {})
        return {
            'output_size': len(str(result)),
            'knowledge_stats': result.get('knowledge_stats', {}),
            'has_analysis': bool(result.get('analysis', '')),
            'analysis_length': len(result.get('analysis', '')),
            'legal_refs_count': len(result.get('applicable_laws', [])),
            'key_facts_count': len(result.get('key_facts', [])),
        }

    def _count_consecutive_failures(self, skill_id: str) -> int:
        """ç»Ÿè®¡è¿ç»­å¤±è´¥æ¬¡æ•°"""
        failures = self.failure_history.get(skill_id, [])
        return len(failures)  # æˆåŠŸæ—¶ä¼šæ¸…ç©ºï¼Œæ‰€ä»¥é•¿åº¦å³è¿ç»­å¤±è´¥æ¬¡æ•°

    def analyze_failures(self, skill_id: str) -> Dict[str, Any]:
        """
        åˆ†æå¤±è´¥åŸå› 

        Returns:
            åŒ…å«ä¸»è¦åŸå› ã€åŸå› åˆ—è¡¨ã€æ¨¡å¼ç»Ÿè®¡
        """
        failures = self.failure_history.get(skill_id, [])
        if not failures:
            return {'primary_cause': 'unknown', 'causes': []}

        causes = []
        recent_failures = failures[-3:]
        num_failures = len(recent_failures)

        # 1. æ£€æŸ¥äº§å‡ºç‰©å¤§å°
        avg_output_size = sum(
            f['execution_result'].get('output_size', 0)
            for f in recent_failures
        ) / num_failures

        if avg_output_size < 500:
            causes.append({
                'type': 'output_too_small',
                'confidence': min(1.0, (500 - avg_output_size) / 500),
                'evidence': 'å¹³å‡äº§å‡ºç‰©å¤§å°: %.0f å­—ç¬¦' % avg_output_size,
            })

        # 2. æ£€æŸ¥çŸ¥è¯†å­˜å‚¨
        avg_stored = sum(
            f['execution_result'].get('knowledge_stats', {}).get('stored', 0)
            for f in recent_failures
        ) / num_failures

        if avg_stored == 0:
            causes.append({
                'type': 'no_knowledge_stored',
                'confidence': 1.0,
                'evidence': 'æœ€è¿‘è®­ç»ƒå‡æœªå­˜å‚¨æ–°çŸ¥è¯†',
            })

        # 3. æ£€æŸ¥åˆ†ææ·±åº¦
        avg_analysis_len = sum(
            f['execution_result'].get('analysis_length', 0)
            for f in recent_failures
        ) / num_failures

        if avg_analysis_len < 200:
            causes.append({
                'type': 'low_analysis_depth',
                'confidence': min(1.0, (200 - avg_analysis_len) / 200),
                'evidence': 'å¹³å‡åˆ†æé•¿åº¦: %.0f å­—ç¬¦' % avg_analysis_len,
            })

        # 4. æ£€æŸ¥æ³•å¾‹å¼•ç”¨
        avg_refs = sum(
            f['execution_result'].get('legal_refs_count', 0)
            for f in recent_failures
        ) / num_failures

        if avg_refs < 2:
            causes.append({
                'type': 'missing_legal_refs',
                'confidence': min(1.0, (2 - avg_refs) / 2),
                'evidence': 'å¹³å‡æ³•å¾‹å¼•ç”¨æ•°: %.1f' % avg_refs,
            })

        # 5. ä»è¯„ä¼°åé¦ˆä¸­æå–
        for f in recent_failures:
            feedback = f.get('feedback', '').lower()
            if 'ç›¸å…³' in feedback and ('ä¸' in feedback or 'ä½' in feedback):
                causes.append({
                    'type': 'low_relevance',
                    'confidence': 0.7,
                    'evidence': 'è¯„ä¼°åé¦ˆæåŠç›¸å…³æ€§é—®é¢˜',
                })
                break

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        causes.sort(key=lambda x: x['confidence'], reverse=True)
        primary_cause = causes[0]['type'] if causes else 'unknown'

        return {
            'primary_cause': primary_cause,
            'primary_cause_desc': self.FAILURE_TYPES.get(primary_cause, 'æœªçŸ¥åŸå› '),
            'causes': causes,
            'patterns': {
                'avg_output_size': avg_output_size,
                'avg_knowledge_stored': avg_stored,
                'avg_analysis_length': avg_analysis_len,
                'avg_legal_refs': avg_refs,
            }
        }

    def generate_optimization_suggestions(
        self,
        skill_id: str,
        failure_analysis: Dict
    ) -> List[Dict]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        causes = failure_analysis.get('causes', [])

        for cause in causes[:3]:
            cause_type = cause['type']
            strategies = self.OPTIMIZATION_STRATEGIES.get(cause_type, [])

            for strategy in strategies:
                suggestion = self._create_suggestion(cause_type, strategy, cause)
                if suggestion:
                    suggestions.append(suggestion)

        suggestions.sort(key=lambda x: x.get('priority', 99))
        return suggestions

    def _create_suggestion(
        self,
        cause_type: str,
        strategy: str,
        cause_info: Dict
    ) -> Optional[Dict]:
        """åˆ›å»ºå…·ä½“çš„ä¼˜åŒ–å»ºè®®"""
        suggestion_templates = {
            ('output_too_small', 'increase_analysis_length'): {
                'description': 'å¢åŠ åˆ†æå†…å®¹çš„é•¿åº¦è¦æ±‚ï¼Œä½¿ç”¨æ›´è¯¦ç»†çš„åˆ†ææ¨¡æ¿',
                'priority': 1,
                'implementation': 'modify_analysis_template',
            },
            ('output_too_small', 'add_more_sections'): {
                'description': 'æ·»åŠ æ›´å¤šåˆ†æç»´åº¦ï¼ˆå¦‚é£é™©åˆ†æã€æ—¶é—´çº¿åˆ†æç­‰ï¼‰',
                'priority': 2,
                'implementation': 'add_sections',
            },
            ('output_too_small', 'use_ai_generation'): {
                'description': 'ä½¿ç”¨ AI ç”Ÿæˆæ›´ä¸°å¯Œçš„åˆ†æå†…å®¹',
                'priority': 3,
                'implementation': 'enable_ai_analysis',
            },
            ('no_knowledge_stored', 'fix_storage_logic'): {
                'description': 'æ£€æŸ¥å¹¶ä¿®å¤çŸ¥è¯†å­˜å‚¨é€»è¾‘ï¼Œç¡®ä¿æœç´¢ç»“æœè¢«æ­£ç¡®å­˜å‚¨',
                'priority': 1,
                'implementation': 'fix_store_knowledge_call',
            },
            ('no_knowledge_stored', 'enable_web_search'): {
                'description': 'å¯ç”¨ç½‘ç»œæœç´¢å¹¶å­˜å‚¨æœç´¢ç»“æœåˆ°çŸ¥è¯†åº“',
                'priority': 2,
                'implementation': 'add_web_search_and_store',
            },
            ('no_knowledge_stored', 'lower_storage_threshold'): {
                'description': 'é™ä½çŸ¥è¯†å­˜å‚¨çš„å†…å®¹é•¿åº¦é˜ˆå€¼',
                'priority': 3,
                'implementation': 'adjust_storage_threshold',
            },
            ('low_analysis_depth', 'add_ai_analysis'): {
                'description': 'æ·»åŠ  AI é©±åŠ¨çš„æ·±åº¦åˆ†æåŠŸèƒ½',
                'priority': 1,
                'implementation': 'integrate_ai_analysis',
            },
            ('low_analysis_depth', 'increase_search_keywords'): {
                'description': 'å¢åŠ æœç´¢å…³é”®è¯æ•°é‡ä»¥è·å–æ›´å¤šèƒŒæ™¯ä¿¡æ¯',
                'priority': 2,
                'implementation': 'expand_keyword_extraction',
            },
            ('low_analysis_depth', 'add_context_integration'): {
                'description': 'æ•´åˆæ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯åˆ°åˆ†æä¸­',
                'priority': 3,
                'implementation': 'enhance_context_usage',
            },
            ('missing_legal_refs', 'add_law_search'): {
                'description': 'æ·»åŠ ä¸“é—¨çš„æ³•å¾‹æ³•è§„æœç´¢',
                'priority': 1,
                'implementation': 'add_law_database_search',
            },
            ('missing_legal_refs', 'add_case_search'): {
                'description': 'æ·»åŠ ç›¸å…³æ¡ˆä¾‹æœç´¢',
                'priority': 2,
                'implementation': 'add_case_search',
            },
            ('low_relevance', 'improve_keyword_extraction'): {
                'description': 'æ”¹è¿›å…³é”®è¯æå–ç®—æ³•ï¼Œä½¿ç”¨ NLP æˆ– AI',
                'priority': 1,
                'implementation': 'enhance_keyword_extraction',
            },
            ('low_relevance', 'add_semantic_search'): {
                'description': 'æ·»åŠ è¯­ä¹‰æœç´¢ä»¥æé«˜ç»“æœç›¸å…³æ€§',
                'priority': 2,
                'implementation': 'add_semantic_search',
            },
        }

        template = suggestion_templates.get((cause_type, strategy))
        if not template:
            return None

        return {
            'cause_type': cause_type,
            'strategy': strategy,
            'description': template['description'],
            'priority': template['priority'],
            'implementation': template['implementation'],
            'evidence': cause_info.get('evidence', ''),
            'confidence': cause_info.get('confidence', 0),
        }

    def apply_optimization(
        self,
        skill_id: str,
        suggestion: Dict
    ) -> Dict[str, Any]:
        """
        åº”ç”¨ä¼˜åŒ–å»ºè®®ï¼ˆä»…åœ¨ auto_optimize=True æ—¶å¯ç”¨ï¼‰

        ç›®å‰å®ç°ä¸ºç”Ÿæˆä¼˜åŒ–æç¤ºï¼Œä¾›äººå·¥å®¡æ ¸ã€‚
        """
        if not self.auto_optimize:
            return {
                'success': False,
                'error': 'auto_optimize is disabled',
                'suggestion': suggestion,
                'requires_review': True,
            }

        # TODO: å®ç°è‡ªåŠ¨ä»£ç ä¿®æ”¹
        return {
            'success': False,
            'error': 'Auto-optimization not yet implemented',
            'suggestion': suggestion,
            'requires_review': True,
        }

    def ai_repair_skill(
        self,
        skill_id: str,
        failure_analysis: Dict[str, Any],
        suggestions: List[Dict],
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM ä¿®å¤è¿ç»­å¤±è´¥çš„æŠ€èƒ½è„šæœ¬

        æµç¨‹ï¼š
        1. è¯»å–æŠ€èƒ½å½“å‰æºç 
        2. æ•´åˆå¤±è´¥åˆ†æ + ä¼˜åŒ–å»ºè®® â†’ æ„é€  prompt
        3. è°ƒç”¨ LLM ç”Ÿæˆä¿®å¤ç‰ˆä»£ç 
        4. è¯­æ³•éªŒè¯
        5. å¤‡ä»½åŸæ–‡ä»¶ â†’ å†™å…¥æ–°ä»£ç 
        6. é‡æ–°åŠ è½½æŠ€èƒ½

        Args:
            skill_id: æŠ€èƒ½ID
            failure_analysis: æ¥è‡ª analyze_failures çš„å¤±è´¥åˆ†æ
            suggestions: æ¥è‡ª generate_optimization_suggestions çš„å»ºè®®åˆ—è¡¨

        Returns:
            {success, skill_id, backup_path, changes_summary, error}
        """
        from pathlib import Path

        logger.info(f"ğŸ”§ å¼€å§‹ AI è‡ªä¿®å¤æŠ€èƒ½: {skill_id}")

        # 1. è¯»å–æŠ€èƒ½å½“å‰æºç 
        library_path = Path("prokaryote_agent/skills/library")
        skill_file = library_path / f"{skill_id}.py"

        if not skill_file.exists():
            return {
                'success': False,
                'skill_id': skill_id,
                'error': f'æŠ€èƒ½æ–‡ä»¶ä¸å­˜åœ¨: {skill_file}',
            }

        original_code = skill_file.read_text(encoding='utf-8')
        logger.info(f"   åŸå§‹ä»£ç : {len(original_code)} å­—ç¬¦")

        # 2. æ„é€ ä¿®å¤ prompt
        prompt = self._build_repair_prompt(
            skill_id, original_code, failure_analysis, suggestions
        )

        # 3. è°ƒç”¨ LLM
        try:
            from prokaryote_agent.ai_adapter import AIAdapter
            ai = AIAdapter()

            if not ai.config.api_key:
                return {
                    'success': False,
                    'skill_id': skill_id,
                    'error': 'AI API Key æœªé…ç½®',
                }

            response = ai._call_ai(prompt)

            if not response.get('success'):
                return {
                    'success': False,
                    'skill_id': skill_id,
                    'error': f"AI è°ƒç”¨å¤±è´¥: {response.get('error')}",
                }

            new_code = self._extract_code_from_response(response['content'])

            if not new_code:
                return {
                    'success': False,
                    'skill_id': skill_id,
                    'error': 'AI è¿”å›å†…å®¹ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆ Python ä»£ç ',
                }

            logger.info(f"   AI ç”Ÿæˆä¿®å¤ä»£ç : {len(new_code)} å­—ç¬¦")

        except Exception as e:
            logger.error(f"   AI ä¿®å¤è°ƒç”¨å¼‚å¸¸: {e}")
            return {
                'success': False,
                'skill_id': skill_id,
                'error': str(e),
            }

        # 4. è¯­æ³•éªŒè¯
        try:
            compile(new_code, f'{skill_id}.py', 'exec')
        except SyntaxError as e:
            logger.error(f"   ä¿®å¤ä»£ç è¯­æ³•é”™è¯¯: {e}")
            return {
                'success': False,
                'skill_id': skill_id,
                'error': f'ä¿®å¤ä»£ç è¯­æ³•é”™è¯¯: {e}',
            }

        # 5. å¤‡ä»½åŸæ–‡ä»¶
        versions_dir = library_path / ".versions"
        versions_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"{skill_id}_pre_repair_{timestamp}.py"
        backup_path = versions_dir / backup_name
        backup_path.write_text(original_code, encoding='utf-8')
        logger.info(f"   å·²å¤‡ä»½: {backup_path}")

        # å†™å…¥ä¿®å¤åçš„ä»£ç 
        skill_file.write_text(new_code, encoding='utf-8')
        logger.info(f"   å·²å†™å…¥ä¿®å¤ä»£ç : {skill_file}")

        # 6. å°è¯•é‡æ–°åŠ è½½
        reload_ok = self._try_reload_skill(skill_id, library_path)

        if not reload_ok:
            # åŠ è½½å¤±è´¥ï¼Œå›æ»š
            logger.warning(f"   ä¿®å¤ä»£ç åŠ è½½å¤±è´¥ï¼Œå›æ»šåˆ°åŸç‰ˆæœ¬")
            skill_file.write_text(original_code, encoding='utf-8')
            return {
                'success': False,
                'skill_id': skill_id,
                'error': 'ä¿®å¤ä»£ç æ— æ³•åŠ è½½ï¼ˆå·²å›æ»šï¼‰',
                'backup_path': str(backup_path),
            }

        # æ¸…ç©ºå¤±è´¥å†å²ï¼ˆç»™ä¿®å¤åçš„ç‰ˆæœ¬ä¸€ä¸ªå¹²å‡€çš„å¼€å§‹ï¼‰
        self.record_success(skill_id)

        # ç”Ÿæˆå˜æ›´æ‘˜è¦
        changes = self._summarize_changes(original_code, new_code)

        logger.info(f"âœ… æŠ€èƒ½ {skill_id} AI è‡ªä¿®å¤æˆåŠŸ")
        for ch in changes[:5]:
            logger.info(f"   - {ch}")

        return {
            'success': True,
            'skill_id': skill_id,
            'backup_path': str(backup_path),
            'changes_summary': changes,
            'code_size_before': len(original_code),
            'code_size_after': len(new_code),
        }

    def _build_repair_prompt(
        self,
        skill_id: str,
        source_code: str,
        failure_analysis: Dict,
        suggestions: List[Dict],
    ) -> str:
        """æ„é€  LLM ä¿®å¤ prompt"""
        # å¤±è´¥åŸå› æè¿°
        causes_text = ""
        for cause in failure_analysis.get('causes', []):
            desc = self.FAILURE_TYPES.get(cause['type'], cause['type'])
            causes_text += f"- {desc} (ç½®ä¿¡åº¦: {cause['confidence']:.0%})\n"
            causes_text += f"  è¯æ®: {cause.get('evidence', '')}\n"

        # ä¼˜åŒ–å»ºè®®æè¿°
        suggestions_text = ""
        for s in suggestions[:5]:
            suggestions_text += f"- [{s.get('strategy')}] {s.get('description')}\n"

        # æ¨¡å¼ç»Ÿè®¡
        patterns = failure_analysis.get('patterns', {})
        patterns_text = ""
        if patterns:
            patterns_text = (
                f"- å¹³å‡äº§å‡ºç‰©å¤§å°: {patterns.get('avg_output_size', 0):.0f} å­—ç¬¦\n"
                f"- å¹³å‡çŸ¥è¯†å­˜å‚¨é‡: {patterns.get('avg_knowledge_stored', 0):.1f} æ¡\n"
                f"- å¹³å‡åˆ†æé•¿åº¦: {patterns.get('avg_analysis_length', 0):.0f} å­—ç¬¦\n"
                f"- å¹³å‡æ³•å¾‹å¼•ç”¨æ•°: {patterns.get('avg_legal_refs', 0):.1f}\n"
            )

        prompt = f"""ä½ æ˜¯ä¸€ä¸ª Python æŠ€èƒ½ä»£ç ä¼˜åŒ–ä¸“å®¶ã€‚è¯·ä¿®å¤ä»¥ä¸‹æŠ€èƒ½ä»£ç ï¼Œä½¿å…¶èƒ½é€šè¿‡è®­ç»ƒè¯„ä¼°ã€‚

## æŠ€èƒ½ ID
{skill_id}

## å½“å‰æºç 
```python
{source_code}
```

## è¿ç»­å¤±è´¥åˆ†æ
{causes_text}

## ç»Ÿè®¡æ•°æ®
{patterns_text}

## ä¼˜åŒ–å»ºè®®
{suggestions_text}

## ä¿®å¤è¦æ±‚
1. ä¿æŒç±»åã€æ–¹æ³•ç­¾åå’Œç»§æ‰¿å…³ç³»ä¸å˜ï¼ˆå¿…é¡»ç»§æ‰¿ Skill åŸºç±»ï¼‰
2. ä¿æŒ `__init__`, `get_capabilities`, `validate_input`, `execute`, `_save_output`, `get_usage_examples` æ–¹æ³•ç­¾åä¸å˜
3. é‡ç‚¹ä¿®å¤ `execute` æ–¹æ³•çš„å®é™…é€»è¾‘
4. ç¡®ä¿ execute è¿”å›æ ¼å¼ä¸º {{'success': True/False, 'result': {{...}}}}
5. å¦‚æœä½¿ç”¨ web_searchï¼Œç¡®ä¿å¤„ç†æœç´¢å¤±è´¥çš„æƒ…å†µï¼ˆtry/exceptï¼‰
6. äº§å‡ºç‰©åº”è¯¥æ›´ä¸°å¯Œå’Œå®Œæ•´ï¼Œä¸åªæ˜¯æ¨¡æ¿æ¡†æ¶
7. å¦‚æœæœ‰ AI é€‚é…å™¨å¯ç”¨ï¼ˆfrom prokaryote_agent.ai_adapter import AIAdapterï¼‰ï¼Œå¯ä»¥ç”¨å®ƒæ¥å¢å¼ºåˆ†æè´¨é‡
8. å¦‚æœæœ‰ SkillContextï¼Œç¡®ä¿é€šè¿‡ context.save_output() ä¿å­˜äº§å‡ºç‰©åˆ°çŸ¥è¯†åº“
9. ä¸è¦å¼•å…¥æ–°çš„å¤–éƒ¨ä¾èµ–ï¼ˆå¯ç”¨æ ‡å‡†åº“ + prokaryote_agent æ¨¡å—å†…çš„ï¼‰

## è¾“å‡ºæ ¼å¼
åªè¾“å‡ºä¿®å¤åçš„å®Œæ•´ Python æ–‡ä»¶å†…å®¹ï¼Œæ”¾åœ¨ ```python ... ``` ä»£ç å—ä¸­ã€‚
ä¸è¦è¾“å‡ºè§£é‡Šæˆ–æ³¨é‡Šï¼Œåªè¦ä»£ç ã€‚"""

        return prompt

    def _extract_code_from_response(self, content: str) -> Optional[str]:
        """ä» LLM å“åº”ä¸­æå– Python ä»£ç å—"""
        if not content:
            return None

        # æŸ¥æ‰¾ ```python ... ``` ä»£ç å—
        import re
        pattern = r'```python\s*\n(.*?)```'
        matches = re.findall(pattern, content, re.DOTALL)

        if matches:
            # å–æœ€é•¿çš„ä»£ç å—ï¼ˆé€šå¸¸æ˜¯å®Œæ•´æ–‡ä»¶ï¼‰
            code = max(matches, key=len).strip()
            if len(code) > 50:  # æœ€å°åˆç†é•¿åº¦
                return code

        # å¤‡é€‰ï¼šå°è¯•æå–æ‰€æœ‰ ``` ä»£ç å—
        pattern2 = r'```\s*\n(.*?)```'
        matches2 = re.findall(pattern2, content, re.DOTALL)
        if matches2:
            code = max(matches2, key=len).strip()
            if len(code) > 50 and 'class ' in code and 'def execute' in code:
                return code

        # æœ€åæ‰‹æ®µï¼šå¦‚æœæ•´ä¸ª content çœ‹èµ·æ¥åƒ Python ä»£ç 
        if 'class ' in content and 'def execute' in content and 'import' in content:
            return content.strip()

        return None

    def _try_reload_skill(self, skill_id: str, library_path) -> bool:
        """å°è¯•é‡æ–°åŠ è½½æŠ€èƒ½æ¨¡å—"""
        import importlib
        import importlib.util
        import sys

        skill_file = library_path / f"{skill_id}.py"

        try:
            # æ¸…é™¤æ—§çš„ç¼“å­˜æ¨¡å—
            if skill_id in sys.modules:
                del sys.modules[skill_id]

            spec = importlib.util.spec_from_file_location(
                skill_id, str(skill_file))
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            # æ£€æŸ¥æ˜¯å¦æœ‰ Skill å­ç±»
            from prokaryote_agent.skills.skill_base import Skill
            found = False
            for name, obj in vars(module).items():
                if (isinstance(obj, type)
                        and issubclass(obj, Skill)
                        and obj is not Skill):
                    found = True
                    break

            return found
        except Exception as e:
            logger.error(f"é‡æ–°åŠ è½½æŠ€èƒ½å¤±è´¥: {e}")
            return False

    def _summarize_changes(
        self, old_code: str, new_code: str
    ) -> List[str]:
        """ç®€è¦æ€»ç»“ä»£ç å˜æ›´"""
        changes = []

        old_lines = old_code.splitlines()
        new_lines = new_code.splitlines()

        # è¡Œæ•°å˜åŒ–
        diff = len(new_lines) - len(old_lines)
        if diff > 0:
            changes.append(f"ä»£ç å¢åŠ äº† {diff} è¡Œ ({len(old_lines)} â†’ {len(new_lines)})")
        elif diff < 0:
            changes.append(f"ä»£ç å‡å°‘äº† {abs(diff)} è¡Œ ({len(old_lines)} â†’ {len(new_lines)})")
        else:
            changes.append(f"ä»£ç è¡Œæ•°ä¸å˜ ({len(new_lines)} è¡Œ)")

        # æ£€æŸ¥å…³é”®å˜æ›´
        old_text = old_code.lower()
        new_text = new_code.lower()

        if 'aiAdapter' in new_code or 'ai_adapter' in new_code:
            if 'ai_adapter' not in old_text:
                changes.append("æ–°å¢: AI é€‚é…å™¨é›†æˆ")

        if 'web_search' in new_text and 'web_search' not in old_text:
            changes.append("æ–°å¢: ç½‘ç»œæœç´¢åŠŸèƒ½")

        if 'context.save_output' in new_text:
            if 'context.save_output' not in old_text:
                changes.append("æ–°å¢: çŸ¥è¯†åº“äº§å‡ºç‰©ä¿å­˜")
            elif new_text.count('context.save_output') > old_text.count('context.save_output'):
                changes.append("å¢å¼º: æ›´å¤šäº§å‡ºç‰©ä¿å­˜åˆ°çŸ¥è¯†åº“")

        if 'try:' in new_text:
            old_try = old_text.count('try:')
            new_try = new_text.count('try:')
            if new_try > old_try:
                changes.append(f"å¢å¼º: é”™è¯¯å¤„ç† ({old_try} â†’ {new_try} ä¸ª try å—)")

        if not changes[1:]:
            changes.append("ä»£ç é€»è¾‘å·²é‡æ„ä¼˜åŒ–")

        return changes


# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
_optimizer: Optional[SkillOptimizer] = None


def get_skill_optimizer(
    max_failures: int = 3,
    auto_optimize: bool = False
) -> SkillOptimizer:
    """è·å–æˆ–åˆ›å»ºæŠ€èƒ½ä¼˜åŒ–å™¨å®ä¾‹"""
    global _optimizer
    if _optimizer is None:
        _optimizer = SkillOptimizer(max_failures, auto_optimize)
    return _optimizer


def record_training_result(
    skill_id: str,
    level: int,
    success: bool,
    eval_result: Dict = None,
    execution_result: Dict = None
) -> Optional[Dict]:
    """
    è®°å½•è®­ç»ƒç»“æœï¼Œå¤±è´¥æ—¶è§¦å‘åˆ†æ

    Args:
        skill_id: æŠ€èƒ½ID
        level: å½“å‰ç­‰çº§
        success: æ˜¯å¦æˆåŠŸ
        eval_result: è¯„ä¼°ç»“æœ
        execution_result: æ‰§è¡Œç»“æœ

    Returns:
        å¤±è´¥æ—¶è¿”å›ä¼˜åŒ–å»ºè®®ï¼ŒæˆåŠŸæ—¶è¿”å› None
    """
    optimizer = get_skill_optimizer()

    if success:
        optimizer.record_success(skill_id)
        return None
    else:
        return optimizer.record_failure(
            skill_id, level,
            eval_result or {},
            execution_result or {}
        )
